method: bon
save: hh-rlhf_llama-3-8b_bon_implicit
save_fmt: json

data_dir: Dahoas/full-hh-rlhf
max_length: 512

llm_dir: meta-llama/Meta-Llama-3-8B-Instruct
draft_dir: /home/bolian/trl_training_toolkit/lblaoke/qwama-0.5b-hh-rlhf-dpo-trl-v4-lr1e-5/checkpoint-4000
rm_dir: argsearch/llama-7b-rm-float32

seed: 1
batch_size: 1
max_new_token: 128
top_k: 40
temperature: 0.8

bon_n: 10
